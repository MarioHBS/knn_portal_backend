# ğŸ§ª SuÃ­te de Testes - Portal de BenefÃ­cios KNN

Esta documentaÃ§Ã£o descreve a configuraÃ§Ã£o completa de testes para os endpoints da API do Portal de BenefÃ­cios KNN.

## ğŸ¯ VisÃ£o Geral

A suÃ­te de testes foi desenvolvida para:

- âœ… **Testar todos os endpoints** da API por perfil de usuÃ¡rio
- ğŸš€ **Inicializar automaticamente** o backend FastAPI
- ğŸ“Š **Gerar relatÃ³rios detalhados** em mÃºltiplos formatos
- ğŸ”§ **ConfiguraÃ§Ã£o centralizada** e flexÃ­vel
- ğŸ“ˆ **MÃ©tricas de performance** e cobertura

### Perfis Testados

- ğŸ‘¨â€ğŸ“ **Student**: Endpoints para estudantes
- ğŸ‘¨â€ğŸ’¼ **Employee**: Endpoints para funcionÃ¡rios
- ğŸ‘¨â€ğŸ’» **Admin**: Endpoints para administradores
- ğŸ¢ **Partner**: Endpoints para parceiros

## ğŸ“ Estrutura do Projeto

```text
scripts/testing/
â”œâ”€â”€ ğŸ“„ README.md                    # Esta documentaÃ§Ã£o
â”œâ”€â”€ âš™ï¸ test_config.py              # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ ğŸ¯ test_runner.py               # Executor principal de testes
â”œâ”€â”€ ğŸ“Š report_generator.py          # Gerador de relatÃ³rios
â”œâ”€â”€ ğŸš€ start_backend.py             # Gerenciador do backend
â”œâ”€â”€ ğŸ® run_all_tests.py             # Script principal
â”œâ”€â”€ ğŸ‘¨â€ğŸ“ test_student_endpoints.py   # Testes de Student
â”œâ”€â”€ ğŸ‘¨â€ğŸ’¼ test_employee_endpoints.py  # Testes de Employee
â”œâ”€â”€ ğŸ‘¨â€ğŸ’» test_admin_endpoints.py     # Testes de Admin
â””â”€â”€ ğŸ¢ test_partner_endpoints.py    # Testes de Partner

reports/                           # RelatÃ³rios gerados
â”œâ”€â”€ ğŸ“„ test_report_YYYYMMDD_HHMMSS.html
â”œâ”€â”€ ğŸ“„ test_report_YYYYMMDD_HHMMSS.json
â”œâ”€â”€ ğŸ“„ test_report_YYYYMMDD_HHMMSS.txt
â””â”€â”€ ğŸ“„ test_execution.log
```

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- FastAPI backend configurado
- DependÃªncias instaladas:

```bash
pip install requests aiohttp fastapi uvicorn
```

### ConfiguraÃ§Ã£o Inicial

1. **Configure os tokens de autenticaÃ§Ã£o** em `test_config.py`:

```python
AUTH_TOKENS = {
    "student": "seu_token_student_aqui",
    "employee": "seu_token_employee_aqui",
    "admin": "seu_token_admin_aqui",
    "partner": "seu_token_partner_aqui"
}
```

2. **Ajuste as URLs base** se necessÃ¡rio:

```python
BASE_URLS = {
    "student": "http://localhost:8000/student",
    "employee": "http://localhost:8000/employee",
    "admin": "http://localhost:8000/admin",
    "partner": "http://localhost:8000/partner",
    "utils": "http://localhost:8000"
}
```

3. **Valide a configuraÃ§Ã£o**:

```bash
cd scripts/testing
python test_config.py
```

## ğŸš€ ExecuÃ§Ã£o dos Testes

### ExecuÃ§Ã£o Completa

Para executar todos os testes com relatÃ³rios:

```bash
cd scripts/testing
python run_all_tests.py
```

### OpÃ§Ãµes de ExecuÃ§Ã£o

```bash
# Testar apenas perfis especÃ­ficos
python run_all_tests.py --profiles student employee

# Modo silencioso
python run_all_tests.py --quiet

# Parar na primeira falha
python run_all_tests.py --stop-on-failure

# NÃ£o gerar relatÃ³rios
python run_all_tests.py --no-reports
```

### ExecuÃ§Ã£o Individual por Perfil

```bash
# Testes de Student
python test_student_endpoints.py

# Testes de Employee
python test_employee_endpoints.py

# Testes de Admin
python test_admin_endpoints.py

# Testes de Partner
python test_partner_endpoints.py
```

### Gerenciamento Manual do Backend

```bash
# Iniciar backend
python start_backend.py start

# Parar backend
python start_backend.py stop

# Reiniciar backend
python start_backend.py restart

# Verificar status
python start_backend.py status
```

## ğŸ“Š RelatÃ³rios

### Formatos DisponÃ­veis

#### ğŸ“„ HTML (Interativo)

- GrÃ¡ficos interativos
- Tabelas filtrÃ¡veis
- Design responsivo
- MÃ©tricas visuais

#### ğŸ“„ JSON (ProgramÃ¡tico)

- Dados estruturados
- IntegraÃ§Ã£o com outras ferramentas
- AnÃ¡lise automatizada

#### ğŸ“„ TXT (Simples)

- Leitura rÃ¡pida
- Logs de execuÃ§Ã£o
- Resumos textuais

### MÃ©tricas IncluÃ­das

- ğŸ“ˆ **Taxa de sucesso** por perfil
- â±ï¸ **Tempos de resposta** (mÃ©dio, mÃ­nimo, mÃ¡ximo)
- ğŸ¯ **Cobertura de endpoints**
- ğŸ“Š **EstatÃ­sticas detalhadas**
- ğŸ” **Resultados individuais**

### LocalizaÃ§Ã£o dos RelatÃ³rios

Todos os relatÃ³rios sÃ£o salvos na pasta `reports/` com timestamp:

```text
reports/
â”œâ”€â”€ test_report_20240115_143022.html
â”œâ”€â”€ test_report_20240115_143022.json
â”œâ”€â”€ test_report_20240115_143022.txt
â””â”€â”€ test_execution.log
```

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### PersonalizaÃ§Ã£o de Testes

Edite `test_config.py` para:

- Adicionar novos endpoints
- Modificar dados de teste
- Ajustar timeouts
- Configurar retry logic

### Exemplo de Novo Endpoint

```python
ENDPOINTS = {
    "student": {
        # Endpoints existentes...
        "new_endpoint": {
            "method": "POST",
            "path": "/new-feature",
            "test_data": {"param": "value"},
            "expected_status": 201
        }
    }
}
```

### ConfiguraÃ§Ã£o de Logging

Ajuste o nÃ­vel de logging em `run_all_tests.py`:

```python
# Mais verboso
logging.basicConfig(level=logging.DEBUG)

# Menos verboso
logging.basicConfig(level=logging.WARNING)
```

## ğŸ”§ Troubleshooting

### Problemas Comuns

#### âŒ Backend nÃ£o inicia

```bash
# Verificar se a porta estÃ¡ em uso
netstat -ano | findstr :8000

# Matar processo se necessÃ¡rio
taskkill /PID <PID> /F
```

#### âŒ Tokens invÃ¡lidos

1. Verifique os tokens em `test_config.py`
2. Gere novos tokens se necessÃ¡rio
3. Teste manualmente com curl:

```bash
curl -H "Authorization: Bearer SEU_TOKEN" http://localhost:8000/student/partners
```

#### âŒ Timeouts

1. Aumente o timeout em `test_config.py`:

```python
REQUEST_TIMEOUT = 60  # segundos
```

2. Verifique a performance do backend

#### âŒ DependÃªncias faltando

```bash
pip install -r requirements.txt
```

### Logs de Debug

Para debug detalhado:

```bash
python run_all_tests.py --verbose
```

Ou verifique o log de execuÃ§Ã£o:

```bash
tail -f reports/test_execution.log
```

### ValidaÃ§Ã£o de ConfiguraÃ§Ã£o

```bash
# Testar configuraÃ§Ã£o
python test_config.py

# Testar conectividade
python -c "import requests; print(requests.get('http://localhost:8000/health').status_code)"
```

## ğŸ“š Exemplos de Uso

### IntegraÃ§Ã£o com CI/CD

```yaml
# .github/workflows/tests.yml
name: API Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: |
          cd scripts/testing
          python run_all_tests.py --no-reports
```

### Script de Monitoramento

```bash
#!/bin/bash
# monitor_api.sh

while true; do
    echo "$(date): Executando testes..."
    cd scripts/testing
    python run_all_tests.py --quiet

    if [ $? -eq 0 ]; then
        echo "âœ… Testes passaram"
    else
        echo "âŒ Testes falharam - enviando alerta"
        # Enviar notificaÃ§Ã£o
    fi

    sleep 300  # 5 minutos
done
```

### AnÃ¡lise de Performance

```python
# analyze_performance.py
import json
from pathlib import Path

# Carregar Ãºltimo relatÃ³rio JSON
reports_dir = Path("reports")
latest_report = max(reports_dir.glob("test_report_*.json"))

with open(latest_report) as f:
    data = json.load(f)

# Analisar tempos de resposta
for result in data["detailed_results"]:
    if result["response_time"] > 1.0:  # > 1 segundo
        print(f"âš ï¸ Endpoint lento: {result['endpoint']} ({result['response_time']:.3f}s)")
```

## ğŸ¤ ContribuiÃ§Ã£o

Para adicionar novos testes:

1. **Crie um novo tester** seguindo o padrÃ£o dos existentes
2. **Adicione configuraÃ§Ãµes** em `test_config.py`
3. **Registre no runner** em `run_all_tests.py`
4. **Teste e documente** as mudanÃ§as

## ğŸ“ Suporte

Para dÃºvidas ou problemas:

1. Consulte os logs em `reports/test_execution.log`
2. Execute com `--verbose` para mais detalhes
3. Verifique a configuraÃ§Ã£o com `python test_config.py`
4. Consulte a documentaÃ§Ã£o da API

---

**Desenvolvido para o Portal de BenefÃ­cios KNN** ğŸš€
